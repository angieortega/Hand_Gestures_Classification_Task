---
title: "Hand Gestures Classification Task Using RF"
output:
  html_document:
    df_print: paged
---

Load the data
Each class of data, CL0, CL1, CL2, and CL3, represent a different hand
gesture: rock, paper, scissors, and okay respectively.
```{r}
CL0 <- read.csv("/Users/angieortega/Downloads/Hand_Gestures_Data/0.csv",header = F)
CL1 <- read.csv("/Users/angieortega/Downloads/Hand_Gestures_Data/1.csv",header = F)
CL2 <- read.csv("/Users/angieortega/Downloads/Hand_Gestures_Data/2.csv",header = F)
CL3 <- read.csv("/Users/angieortega/Downloads/Hand_Gestures_Data/3.csv",header = F)
```

1. Preliminary treatment of the data set

  1.1 Displaying the size of each class of data as number and as a percentage
```{r}
# Size of each class of data
n0 = nrow(CL0) 
n1 = nrow(CL1)
n2 = nrow(CL2) 
n3 = nrow(CL3)

# Total size of the data set
N = n0 + n1 + n2 + n3

# Size of each class of data as percentage
Pn0 = n0/N  
Pn1 = n1/N 
Pn2 = n2/N 
Pn3 = n3/N
```

 1.2 Normalization of data
```{r}
DATA = rbind(CL0, CL1, CL2,CL3)
start = 1
end = 64
x = DATA[,start: end]
normalize <- function(x) {
  return ((x - mean(x)) / (sd(x))) }
SDATA= sapply(x, normalize)
```
 
 1.3 Principal Component Analysis (PCA) to find the ideal number of features for RF
```{r}
R = cor(x)
D = eigen(R)$values
Q = eigen(R)$vectors
p = order(abs(cumsum(D)/sum(D) - 0.95), decreasing = FALSE)[1]
```

 1.4 Training set and Test set for each class
```{r} 
r0 = round(n0 * .2)
s0 = n0 - r0
r1 = round(n1 * .2)
s1 = n1 - r1
r2 = round(n2 * .2)
s2 = n2 - r2
r3 = round(n3 * .2)
s3 = n3 - r3

set.seed(100)
# Training set for each class
train.CL0 = CL0[1:s0,c(1, start:end+1)]
train.CL1 = CL1[1:s1,c(1, start:end+1)]
train.CL2 = CL2[1:s2,c(1, start:end+1)]
train.CL3 = CL3[1:s3,c(1, start:end+1)]

# Test set for each class
test.CL0 = CL0[(s0+1):n0,c(1, start:end+1)]
test.CL1 = CL1[(s1+1):n1,c(1, start:end+1)]
test.CL2 = CL2[(s2+1):n2,c(1, start:end+1)]
test.CL3 = CL3[(s3+1):n3,c(1, start:end+1)]
```

 1.5 Regroup training and test sets across all classes and obtain class labels (True class
 of each observation)
```{r}
# Final Training set 
trainset = rbind(SDATA[1:s0,],SDATA[(n0+1):(n0+s1),],
                 SDATA[(n0+n1+1):(n0+n1+s2),],SDATA[(n0+n1+n2+1):(n0+n1+n2+s3),])

# Final Testing set
testset = rbind(SDATA[(s0+1):n0,], SDATA[(n0+s1+1):(n0+n1),], 
                SDATA[(n0+n1+s2+1):(n0+n1+n2),], SDATA[(n0+n1+n2+s3+1):(n0+n1+n2+n3),])

# Labels (True class) for Training and Testing sets
trainset_labels = rbind(train.CL0, train.CL1, train.CL2, train.CL3)[,65] 
testset_labels = rbind(test.CL0, test.CL1, test.CL2, test.CL3)[,65] 
```

2. Training the Random Forest (RF) classifier

 2.1 Loading required libraries
```{r}
library(caret)
library(randomForest) 
```

 2.2 Converting labels of training set to factor form
```{r}
trainset_labels <- as.factor(trainset_labels)
```

 2.3 Training and Testing the RF classifier on the training set for 100 trees

  2.3.1 Training the RF classifier
```{r}
rf.100 = randomForest(trainset_labels~., data = trainset, ntree = 100, mtry = sqrt(p))
trainp.100 = predict(rf.100, trainset)
rf.100
```

  2.3.2 Confusion Table and Accuracy for Training set
```{r}
trainconftab.100 = confusionMatrix(trainp.100, as.factor(trainset_labels))$table
trainconftab.100
trainperfo.100 = confusionMatrix(trainp.100, as.factor(trainset_labels))$overall[1]
trainperfo.100
```
  
  2.3.3 Testing the RF classifier
```{r}
testp.100 = predict(rf.100,testset)
```

  2.3.4 Confusion Table and Accuracy for Testing set
```{r}
testconftab.100 = confusionMatrix(testp.100, as.factor(testset_labels))$table
testconftab.100
testperfo.100 = confusionMatrix(testp.100,as.factor(testset_labels))$overall[1]
testperfo.100
```
  
  2.4 Training and Testing the RF classifier on the training set for 200 trees
  
   2.4.1 Training the RF classifier
```{r} 
rf.200 = randomForest(trainset_labels~., data = trainset, ntree = 200, mtry = sqrt(p)) #21"
trainp.200 = predict(rf.200, trainset)
rf.200
```
  
   2.4.2 Confusion Table and Accuracy for Training set
```{r}
trainconftab.200 = confusionMatrix(trainp.200, as.factor(trainset_labels))$table
trainconftab.200
trainperfo.200 = confusionMatrix(trainp.200, as.factor(trainset_labels))$overall[1]
trainperfo.200
```

   2.4.3 Testing the RF classifier
```{r}
testp.200 = predict(rf.200,testset)
```

   2.4.4 Confusion Table and Accuracy for Testing set
```{r}
testconftab.200 = confusionMatrix(testp.200, as.factor(testset_labels))$table
testconftab.200
testperfo.200 = confusionMatrix(testp.200,as.factor(testset_labels))$overall[1]
testperfo.200
```


  2.5 Training and Testing the RF classifier on the training set for 300 trees
  
   2.5.1 Training the RF classifier
```{r} 
rf.300 = randomForest(trainset_labels~., data = trainset, ntree = 300, mtry = sqrt(p)) #21"
trainp.300 = predict(rf.300, trainset)
rf.300
```
  
   2.5.2 Confusion Table and Accuracy for Training set
```{r}
trainconftab.300 = confusionMatrix(trainp.300, as.factor(trainset_labels))$table
trainconftab.300
trainperfo.300 = confusionMatrix(trainp.300, as.factor(trainset_labels))$overall[1]
trainperfo.300
```

   2.5.3 Testing the RF classifier
```{r}
testp.300 = predict(rf.300,testset)
```

   2.5.4 Confusion Table and Accuracy for Testing set
```{r}
testconftab.300 = confusionMatrix(testp.300, as.factor(testset_labels))$table
testconftab.300
testperfo.300 = confusionMatrix(testp.300,as.factor(testset_labels))$overall[1]
testperfo.300
```

 3. Calculating Importance of features for 100 trees
```{r}
RF.100 = randomForest(trainset_labels~., data = trainset, ntree = 100, 
                      mtry = sqrt(p), importance = TRUE)

varImpPlot(RF.100, sort=TRUE, n.var= 10, type=NULL, class=NULL, 
           scale=TRUE, main = 'Importance Top 10 Features')

```
